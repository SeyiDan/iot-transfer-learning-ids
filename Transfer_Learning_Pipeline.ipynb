{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Setup & Configuration"
      ],
      "metadata": {
        "id": "AtTFAhDCas__"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmnnNI6TapGG"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Machine Learning Models\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"All libraries imported successfully\")\n",
        "\n",
        "# Configuration\n",
        "ALIGNED_DIR = '/content/drive/My Drive/Project_Final_Submission/enhanced_aligned_datasets'\n",
        "RESULTS_DIR = '/content/drive/My Drive/Project_Final_Submission/transfer_learning_results'\n",
        "\n",
        "# Create results directory\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Aligned datasets: {ALIGNED_DIR}\")\n",
        "print(f\"Results will be saved to: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if directory exists\n",
        "base_dir = '/content/drive/My Drive/Project_Final_Submission/enhanced_aligned_datasets'\n",
        "if os.path.exists(base_dir):\n",
        "    print(f\"Directory exists: {base_dir}\")\n",
        "    files = os.listdir(base_dir)\n",
        "    print(f\"Files found: {len(files)}\")\n",
        "    for f in files:\n",
        "        print(f\"  - {f}\")\n",
        "else:\n",
        "    print(f\"Directory NOT found: {base_dir}\")\n",
        "\n",
        "# Check parent directory\n",
        "parent = '/content/drive/My Drive/Project_Final_Submission'\n",
        "if os.path.exists(parent):\n",
        "    print(f\"\\nParent exists: {parent}\")\n",
        "    folders = os.listdir(parent)\n",
        "    print(f\"Folders: {folders}\")\n",
        "else:\n",
        "    print(f\"\\nParent NOT found: {parent}\")"
      ],
      "metadata": {
        "id": "Ta4mekxDqT_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Target Datasets & Models"
      ],
      "metadata": {
        "id": "3xoI16WTa2BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset pairs (source, target)\n",
        "# Note: IDS-2018 removed due to no common classes\n",
        "DATASETS = {\n",
        "    'CIC-IoT': (\n",
        "        f'{ALIGNED_DIR}/enhanced_aligned_ciciomt_for_cic-iot.pkl',\n",
        "        f'{ALIGNED_DIR}/enhanced_aligned_cic-iot.pkl'\n",
        "    ),\n",
        "    'IoT-23': (\n",
        "        f'{ALIGNED_DIR}/enhanced_aligned_ciciomt_for_iot-23.pkl',\n",
        "        f'{ALIGNED_DIR}/enhanced_aligned_iot-23.pkl'\n",
        "    )\n",
        "}\n",
        "\n",
        "# Common classes across all datasets\n",
        "COMMON_CLASSES = ['DoS', 'Reconnaissance']\n",
        "\n",
        "# Define models with optimized hyperparameters\n",
        "MODELS = {\n",
        "    'RandomForest': RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=20,\n",
        "        min_samples_split=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'GradientBoosting': GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'SVM': SVC(\n",
        "        kernel='rbf',\n",
        "        C=1.0,\n",
        "        gamma='scale',\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    'MLP': MLPClassifier(\n",
        "        hidden_layer_sizes=(128, 64),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        max_iter=500,\n",
        "        random_state=42,\n",
        "        early_stopping=True,\n",
        "        validation_fraction=0.1\n",
        "    ),\n",
        "    'XGBoost': XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "}\n",
        "\n",
        "print(f\"Target datasets: {list(DATASETS.keys())}\")\n",
        "print(f\"Common classes: {COMMON_CLASSES}\")\n",
        "print(f\"Models: {list(MODELS.keys())}\")"
      ],
      "metadata": {
        "id": "pokH_2DEa4bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading & Filtering Functions"
      ],
      "metadata": {
        "id": "1S4zFr8FbVhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filepath):\n",
        "    \"\"\"Load preprocessed dataset from pickle file\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def filter_to_common_classes(X, y, common_classes):\n",
        "    \"\"\"Filter dataset to only include common classes\"\"\"\n",
        "    # Convert to pandas if needed\n",
        "    if not isinstance(y, pd.Series):\n",
        "        y = pd.Series(y)\n",
        "    if not isinstance(X, pd.DataFrame):\n",
        "        X = pd.DataFrame(X)\n",
        "\n",
        "    # Reset indices\n",
        "    X = X.reset_index(drop=True)\n",
        "    y = y.reset_index(drop=True)\n",
        "\n",
        "    # Filter\n",
        "    mask = y.isin(common_classes)\n",
        "    X_filtered = X[mask].reset_index(drop=True)\n",
        "    y_filtered = y[mask].reset_index(drop=True)\n",
        "\n",
        "    return X_filtered, y_filtered\n",
        "\n",
        "\n",
        "def prepare_transfer_data(source_file, target_file, common_classes):\n",
        "    \"\"\"\n",
        "    Load and prepare source and target data for transfer learning\n",
        "    Returns: X_train, y_train, X_test, y_test (all filtered to common classes)\n",
        "    \"\"\"\n",
        "    print(\"\\nLoading datasets...\")\n",
        "\n",
        "    # Load data\n",
        "    source_data = load_dataset(source_file)\n",
        "    target_data = load_dataset(target_file)\n",
        "\n",
        "    if source_data is None or target_data is None:\n",
        "        return None, None, None, None\n",
        "\n",
        "    print(f\"   Source loaded: {len(source_data['train_x'])} training samples\")\n",
        "    print(f\"   Target loaded: {len(target_data['test_x'])} test samples\")\n",
        "\n",
        "    # Extract data\n",
        "    X_train_source = source_data['train_x']\n",
        "    y_train_source = source_data['train_y']\n",
        "    X_test_target = target_data['test_x']\n",
        "    y_test_target = target_data['test_y']\n",
        "\n",
        "    print(f\"\\nOriginal class distributions:\")\n",
        "    print(f\"   Source classes: {sorted(y_train_source.unique())}\")\n",
        "    print(f\"   Target classes: {sorted(y_test_target.unique())}\")\n",
        "\n",
        "    # Filter to common classes\n",
        "    print(f\"\\nFiltering to common classes: {common_classes}\")\n",
        "    X_train, y_train = filter_to_common_classes(X_train_source, y_train_source, common_classes)\n",
        "    X_test, y_test = filter_to_common_classes(X_test_target, y_test_target, common_classes)\n",
        "\n",
        "    print(f\"\\nAfter filtering:\")\n",
        "    print(f\"   Source training: {len(y_train)} samples\")\n",
        "    print(f\"   Target testing: {len(y_test)} samples\")\n",
        "    print(f\"\\n   Training distribution:\")\n",
        "    print(y_train.value_counts().to_string())\n",
        "    print(f\"\\n   Testing distribution:\")\n",
        "    print(y_test.value_counts().to_string())\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "print(\"Data loading functions defined\")"
      ],
      "metadata": {
        "id": "LHrSdH4TbVOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation & Visualization Functions"
      ],
      "metadata": {
        "id": "f_59SyE0bcny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_confusion_matrix(y_true, y_pred, classes, model_name, dataset_name):\n",
        "    \"\"\"Generate and save confusion matrix visualization\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes,\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.title(f'Confusion Matrix: {model_name} on {dataset_name}\\n(Transfer Learning from CICIOMT)',\n",
        "              fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=11)\n",
        "    plt.xlabel('Predicted Label', fontsize=11)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    filename = f'{RESULTS_DIR}/cm_{model_name}_{dataset_name}.png'\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"      Confusion matrix saved\")\n",
        "\n",
        "\n",
        "def generate_classification_report(y_true, y_pred, classes, model_name, dataset_name):\n",
        "    \"\"\"Generate and save detailed classification report\"\"\"\n",
        "\n",
        "    # Generate report\n",
        "    report_dict = classification_report(y_true, y_pred, target_names=classes,\n",
        "                                        output_dict=True, zero_division=0)\n",
        "\n",
        "    # Display report\n",
        "    print(f\"\\n      Classification Report:\")\n",
        "    print(\"      \" + \"=\"*60)\n",
        "    report_str = classification_report(y_true, y_pred, target_names=classes, zero_division=0)\n",
        "    for line in report_str.split('\\n'):\n",
        "        print(f\"      {line}\")\n",
        "    print(\"      \" + \"=\"*60)\n",
        "\n",
        "    # Save to CSV\n",
        "    df_report = pd.DataFrame(report_dict).transpose()\n",
        "    filename = f'{RESULTS_DIR}/report_{model_name}_{dataset_name}.csv'\n",
        "    df_report.to_csv(filename)\n",
        "    print(f\"      Report saved to CSV\")\n",
        "\n",
        "    return report_dict\n",
        "\n",
        "\n",
        "print(\"Evaluation functions defined\")"
      ],
      "metadata": {
        "id": "sPUsuMU2bcX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Transfer Learning Training Loop"
      ],
      "metadata": {
        "id": "2zf4CzXDbkqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store all results\n",
        "all_results = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING TRANSFER LEARNING EXPERIMENTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Source Domain: CICIOMT (Medical IoT)\")\n",
        "print(f\"Target Domains: {list(DATASETS.keys())}\")\n",
        "print(f\"Common Classes: {COMMON_CLASSES}\")\n",
        "print(f\"Models: {list(MODELS.keys())}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Iterate through each target dataset\n",
        "for dataset_name, (source_file, target_file) in DATASETS.items():\n",
        "\n",
        "    print(\"\\n\" + \"-\"*35)\n",
        "    print(f\"TARGET DATASET: {dataset_name}\")\n",
        "    print(\"-\"*35)\n",
        "\n",
        "    # Load and prepare data\n",
        "    X_train, y_train, X_test, y_test = prepare_transfer_data(\n",
        "        source_file, target_file, COMMON_CLASSES\n",
        "    )\n",
        "\n",
        "    if X_train is None:\n",
        "        print(f\"Skipping {dataset_name} due to data loading error\")\n",
        "        continue\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_enc = label_encoder.fit_transform(y_train)\n",
        "    y_test_enc = label_encoder.transform(y_test)\n",
        "\n",
        "    classes = label_encoder.classes_\n",
        "    print(f\"\\nEncoded classes: {classes}\")\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_train_np = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
        "    X_test_np = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n",
        "\n",
        "    # Train each model\n",
        "    for model_name, model in MODELS.items():\n",
        "\n",
        "        print(f\"\\n   {'='*60}\")\n",
        "        print(f\"   MODEL: {model_name}\")\n",
        "        print(f\"   {'='*60}\")\n",
        "\n",
        "        try:\n",
        "            # Train on source\n",
        "            print(f\"      Training on CICIOMT source data...\")\n",
        "            start_time = time.time()\n",
        "            model.fit(X_train_np, y_train_enc)\n",
        "            train_time = time.time() - start_time\n",
        "\n",
        "            # Predict on target\n",
        "            print(f\"      Predicting on {dataset_name} target data...\")\n",
        "            y_pred_enc = model.predict(X_test_np)\n",
        "            y_pred = label_encoder.inverse_transform(y_pred_enc)\n",
        "\n",
        "            # Measure prediction time (averaged over all samples)\n",
        "            print(f\"      Measuring inference time...\")\n",
        "            pred_start = time.time()\n",
        "            _ = model.predict(X_test_np)\n",
        "            pred_time_total = time.time() - pred_start\n",
        "            pred_time_per_sample = (pred_time_total / len(X_test_np)) * 1000  # ms per sample\n",
        "\n",
        "            # Calculate standard metrics\n",
        "            accuracy = accuracy_score(y_test_enc, y_pred_enc)\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                y_test_enc, y_pred_enc, average='weighted', zero_division=0\n",
        "            )\n",
        "\n",
        "            # Calculate confusion matrix for FPR/FNR\n",
        "            cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
        "\n",
        "            # Calculate FPR and FNR for each class\n",
        "            fpr_list = []\n",
        "            fnr_list = []\n",
        "            fpr_per_class = {}\n",
        "            fnr_per_class = {}\n",
        "\n",
        "            for i, cls in enumerate(classes):\n",
        "                TP = cm[i, i]\n",
        "                FP = cm[:, i].sum() - TP\n",
        "                FN = cm[i, :].sum() - TP\n",
        "                TN = cm.sum() - (TP + FP + FN)\n",
        "\n",
        "                # False Positive Rate\n",
        "                fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
        "\n",
        "                # False Negative Rate (Miss Rate)\n",
        "                fnr = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
        "\n",
        "                fpr_list.append(fpr)\n",
        "                fnr_list.append(fnr)\n",
        "                fpr_per_class[cls] = fpr\n",
        "                fnr_per_class[cls] = fnr\n",
        "\n",
        "            # Average FPR and FNR\n",
        "            avg_fpr = np.mean(fpr_list)\n",
        "            avg_fnr = np.mean(fnr_list)\n",
        "\n",
        "            # Display results\n",
        "            print(f\"\\n      RESULTS:\")\n",
        "            print(f\"         Accuracy:        {accuracy:.3f}\")\n",
        "            print(f\"         Precision:       {precision:.3f}\")\n",
        "            print(f\"         Recall:          {recall:.3f}\")\n",
        "            print(f\"         F1-Score:        {f1:.3f}\")\n",
        "            print(f\"         Avg FPR:         {avg_fpr:.3f}\")\n",
        "            print(f\"         Avg FNR:         {avg_fnr:.3f}\")\n",
        "            print(f\"         Training Time:   {train_time:.2f}s\")\n",
        "            print(f\"         Prediction Time: {pred_time_per_sample:.3f}ms/sample\")\n",
        "\n",
        "            # Display per-class FPR/FNR\n",
        "            print(f\"\\n      Per-Class Security Metrics:\")\n",
        "            for cls in classes:\n",
        "                print(f\"         {cls:15s} - FPR: {fpr_per_class[cls]:.3f}, FNR: {fnr_per_class[cls]:.3f}\")\n",
        "\n",
        "            # Generate visualizations\n",
        "            save_confusion_matrix(y_test, y_pred, classes, model_name, dataset_name)\n",
        "            report = generate_classification_report(y_test, y_pred, classes, model_name, dataset_name)\n",
        "\n",
        "            # Store comprehensive results\n",
        "            result_entry = {\n",
        "                'Source': 'CICIOMT',\n",
        "                'Target': dataset_name,\n",
        "                'Model': model_name,\n",
        "                'Accuracy': accuracy,\n",
        "                'Precision': precision,\n",
        "                'Recall': recall,\n",
        "                'F1_Score': f1,\n",
        "                'Avg_FPR': avg_fpr,\n",
        "                'Avg_FNR': avg_fnr,\n",
        "                'Training_Time_sec': train_time,\n",
        "                'Prediction_Time_ms': pred_time_per_sample,\n",
        "                'Train_Samples': len(y_train),\n",
        "                'Test_Samples': len(y_test),\n",
        "                'Classes': ', '.join(classes)\n",
        "            }\n",
        "\n",
        "            # Add per-class metrics\n",
        "            for cls in classes:\n",
        "                result_entry[f'{cls}_FPR'] = fpr_per_class[cls]\n",
        "                result_entry[f'{cls}_FNR'] = fnr_per_class[cls]\n",
        "\n",
        "            all_results.append(result_entry)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n      Error training {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Store failed result\n",
        "            failed_entry = {\n",
        "                'Source': 'CICIOMT',\n",
        "                'Target': dataset_name,\n",
        "                'Model': model_name,\n",
        "                'Accuracy': 0.0,\n",
        "                'Precision': 0.0,\n",
        "                'Recall': 0.0,\n",
        "                'F1_Score': 0.0,\n",
        "                'Avg_FPR': 0.0,\n",
        "                'Avg_FNR': 1.0,\n",
        "                'Training_Time_sec': 0.0,\n",
        "                'Prediction_Time_ms': 0.0,\n",
        "                'Train_Samples': len(y_train) if y_train is not None else 0,\n",
        "                'Test_Samples': len(y_test) if y_test is not None else 0,\n",
        "                'Classes': ', '.join(COMMON_CLASSES)\n",
        "            }\n",
        "\n",
        "            # Add placeholder per-class metrics\n",
        "            for cls in COMMON_CLASSES:\n",
        "                failed_entry[f'{cls}_FPR'] = 0.0\n",
        "                failed_entry[f'{cls}_FNR'] = 1.0\n",
        "\n",
        "            all_results.append(failed_entry)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL EXPERIMENTS COMPLETED!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "TO5RwZxrbk9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enhanced Results Summary"
      ],
      "metadata": {
        "id": "SaGFrUyMkvMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame\n",
        "df_results = pd.DataFrame(all_results)\n",
        "\n",
        "# Display full results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPLETE TRANSFER LEARNING RESULTS (WITH SECURITY METRICS)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Select key columns for display\n",
        "display_cols = ['Target', 'Model', 'Accuracy', 'F1_Score', 'Avg_FPR',\n",
        "                'Avg_FNR', 'Training_Time_sec', 'Prediction_Time_ms']\n",
        "print(df_results[display_cols].to_string(index=False))\n",
        "\n",
        "# Save complete results\n",
        "results_file = f'{RESULTS_DIR}/transfer_learning_complete_results_enhanced.csv'\n",
        "df_results.to_csv(results_file, index=False)\n",
        "print(f\"\\nComplete results saved: {results_file}\")\n",
        "\n",
        "# Security Metrics Analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SECURITY METRICS ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for target in df_results['Target'].unique():\n",
        "    print(f\"\\n{target}:\")\n",
        "    target_df = df_results[df_results['Target'] == target]\n",
        "\n",
        "    print(\"\\n   Model Performance (Sorted by Accuracy):\")\n",
        "    security_view = target_df[['Model', 'Accuracy', 'Avg_FPR', 'Avg_FNR']].sort_values('Accuracy', ascending=False)\n",
        "    print(security_view.to_string(index=False))\n",
        "\n",
        "    # Identify best model for security\n",
        "    best_security = target_df.loc[target_df['Avg_FPR'].idxmin()]\n",
        "    print(f\"\\n   Best Security (Lowest FPR): {best_security['Model']}\")\n",
        "    print(f\"      FPR: {best_security['Avg_FPR']:.3f}, FNR: {best_security['Avg_FNR']:.3f}\")\n",
        "\n",
        "# Computational Efficiency Analysis\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPUTATIONAL EFFICIENCY ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for target in df_results['Target'].unique():\n",
        "    print(f\"\\n{target}:\")\n",
        "    target_df = df_results[df_results['Target'] == target]\n",
        "\n",
        "    efficiency_view = target_df[['Model', 'Accuracy', 'Training_Time_sec', 'Prediction_Time_ms']].sort_values('Prediction_Time_ms')\n",
        "    print(efficiency_view.to_string(index=False))\n",
        "\n",
        "    # Best efficiency model\n",
        "    best_efficiency = target_df.loc[target_df['Prediction_Time_ms'].idxmin()]\n",
        "    print(f\"\\n   Fastest Inference: {best_efficiency['Model']}\")\n",
        "    print(f\"      {best_efficiency['Prediction_Time_ms']:.3f}ms/sample (Accuracy: {best_efficiency['Accuracy']:.3f})\")\n",
        "\n",
        "# Create accuracy pivot table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ACCURACY COMPARISON TABLE\")\n",
        "print(\"=\"*70)\n",
        "pivot_accuracy = df_results.pivot(index='Model', columns='Target', values='Accuracy')\n",
        "print(pivot_accuracy.to_string())\n",
        "\n",
        "# Save pivot tables\n",
        "pivot_accuracy.to_csv(f'{RESULTS_DIR}/accuracy_comparison.csv')\n",
        "print(f\"\\nAccuracy table saved\")\n",
        "\n",
        "# FPR/FNR pivot tables\n",
        "pivot_fpr = df_results.pivot(index='Model', columns='Target', values='Avg_FPR')\n",
        "pivot_fnr = df_results.pivot(index='Model', columns='Target', values='Avg_FNR')\n",
        "\n",
        "pivot_fpr.to_csv(f'{RESULTS_DIR}/fpr_comparison.csv')\n",
        "pivot_fnr.to_csv(f'{RESULTS_DIR}/fnr_comparison.csv')\n",
        "print(f\"FPR/FNR tables saved\")\n",
        "\n",
        "# Overall statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OVERALL STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Mean Accuracy:          {df_results['Accuracy'].mean():.3f}\")\n",
        "print(f\"Mean F1-Score:          {df_results['F1_Score'].mean():.3f}\")\n",
        "print(f\"Mean FPR:               {df_results['Avg_FPR'].mean():.3f}\")\n",
        "print(f\"Mean FNR:               {df_results['Avg_FNR'].mean():.3f}\")\n",
        "print(f\"Mean Training Time:     {df_results['Training_Time_sec'].mean():.2f}s\")\n",
        "print(f\"Mean Prediction Time:   {df_results['Prediction_Time_ms'].mean():.3f}ms\")\n",
        "print(f\"\\nBest Overall Accuracy:  {df_results['Accuracy'].max():.3f}\")\n",
        "print(f\"Lowest FPR:             {df_results['Avg_FPR'].min():.3f}\")\n",
        "print(f\"Fastest Prediction:     {df_results['Prediction_Time_ms'].min():.3f}ms\")"
      ],
      "metadata": {
        "id": "Hl82i2TZkvkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Summary & Analysis"
      ],
      "metadata": {
        "id": "5C0u0cr2bu1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame\n",
        "df_results = pd.DataFrame(all_results)\n",
        "\n",
        "# Display full results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPLETE TRANSFER LEARNING RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(df_results.to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "results_file = f'{RESULTS_DIR}/transfer_learning_complete_results.csv'\n",
        "df_results.to_csv(results_file, index=False)\n",
        "print(f\"\\nComplete results saved: {results_file}\")\n",
        "\n",
        "# Create accuracy pivot table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ACCURACY COMPARISON TABLE\")\n",
        "print(\"=\"*70)\n",
        "pivot_accuracy = df_results.pivot(index='Model', columns='Target', values='Accuracy')\n",
        "print(pivot_accuracy.to_string())\n",
        "\n",
        "# Save pivot table\n",
        "pivot_file = f'{RESULTS_DIR}/accuracy_comparison.csv'\n",
        "pivot_accuracy.to_csv(pivot_file)\n",
        "print(f\"\\nAccuracy table saved: {pivot_file}\")\n",
        "\n",
        "# Best model per target\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BEST PERFORMING MODELS\")\n",
        "print(\"=\"*70)\n",
        "for target in df_results['Target'].unique():\n",
        "    best = df_results[df_results['Target'] == target].nlargest(1, 'Accuracy')\n",
        "    print(f\"{target:15s} -> {best.iloc[0]['Model']:20s} \"\n",
        "          f\"(Accuracy: {best.iloc[0]['Accuracy']:.3f}, \"\n",
        "          f\"F1: {best.iloc[0]['F1_Score']:.3f})\")\n",
        "\n",
        "# Overall statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OVERALL STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Mean Accuracy:     {df_results['Accuracy'].mean():.3f}\")\n",
        "print(f\"Std Accuracy:      {df_results['Accuracy'].std():.3f}\")\n",
        "print(f\"Best Accuracy:     {df_results['Accuracy'].max():.3f}\")\n",
        "print(f\"Worst Accuracy:    {df_results['Accuracy'].min():.3f}\")\n",
        "print(f\"Mean Training Time: {df_results['Training_Time_sec'].mean():.2f}s\")"
      ],
      "metadata": {
        "id": "EGPbfei-bvXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Summary Report"
      ],
      "metadata": {
        "id": "llJsFASHb645"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"-\"*35)\n",
        "print(\"TRANSFER LEARNING EXPERIMENT SUMMARY\")\n",
        "print(\"-\"*35)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"EXPERIMENTAL SETUP\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Source Domain:        CICIOMT (Medical IoT - WiFi/MQTT)\")\n",
        "print(f\"Target Domains:       CIC-IoT, IoT-23\")\n",
        "print(f\"Common Classes:       {', '.join(COMMON_CLASSES)}\")\n",
        "print(f\"Models Evaluated:     {len(MODELS)}\")\n",
        "print(f\"Total Experiments:    {len(df_results)}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"KEY FINDINGS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Per-target analysis\n",
        "for target in df_results['Target'].unique():\n",
        "    target_results = df_results[df_results['Target'] == target]\n",
        "    best_model = target_results.nlargest(1, 'Accuracy').iloc[0]\n",
        "\n",
        "    print(f\"\\n{target}:\")\n",
        "    print(f\"   Best Model:      {best_model['Model']}\")\n",
        "    print(f\"   Best Accuracy:   {best_model['Accuracy']:.3f}\")\n",
        "    print(f\"   Best F1-Score:   {best_model['F1_Score']:.3f}\")\n",
        "    print(f\"   Training Time:   {best_model['Training_Time_sec']:.2f}s\")\n",
        "    print(f\"   Test Samples:    {best_model['Test_Samples']}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"THESIS CONTRIBUTIONS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(\"\"\"\n",
        "Novel Application: First study using medical IoT (CICIOMT) as transfer\n",
        "  learning source for general IoT intrusion detection\n",
        "\n",
        "Cross-Domain Analysis: Quantified accuracy gaps between medical and\n",
        "  general IoT domains, demonstrating protocol-specific challenges\n",
        "\n",
        "Model Comparison: Evaluated 5 ML algorithms, showing ensemble methods\n",
        "  (Random Forest, XGBoost) outperform neural networks for low-resource\n",
        "  transfer learning scenarios\n",
        "\n",
        "Practical Insights: Training time vs accuracy tradeoffs inform real-world\n",
        "  deployment decisions for resource-constrained IoT devices\n",
        "\"\"\")\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"FILES SAVED\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Location: {RESULTS_DIR}\")\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"   transfer_learning_complete_results.csv\")\n",
        "print(f\"   accuracy_comparison.csv\")\n",
        "print(f\"\\nVisualizations:\")\n",
        "print(f\"   accuracy_comparison_chart.png\")\n",
        "print(f\"   training_time_comparison.png\")\n",
        "print(f\"   performance_heatmap.png\")\n",
        "print(f\"   f1_score_comparison.png\")\n",
        "print(f\"\\nPer-Model Results:\")\n",
        "for target in df_results['Target'].unique():\n",
        "    for model in df_results['Model'].unique():\n",
        "        print(f\"   cm_{model}_{target}.png\")\n",
        "        print(f\"   report_{model}_{target}.csv\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"EXPERIMENT COMPLETE - READY FOR THESIS SUBMISSION\")\n",
        "print(f\"{'='*70}\\n\")"
      ],
      "metadata": {
        "id": "4B8s9yRYb7QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizations"
      ],
      "metadata": {
        "id": "HMf5RIp3mW8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FIGURE 1: Model Training Time Comparison Across Datasets"
      ],
      "metadata": {
        "id": "JbW6GkKJmgtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set publication-quality style\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "\n",
        "def create_figure1():\n",
        "    training_data = {\n",
        "        'CIC-IoT': {\n",
        "            'XGBoost': 1.00,\n",
        "            'RandomForest': 1.70,\n",
        "            'SVM': 0.57,\n",
        "            'MLP': 13.84,\n",
        "            'GradientBoosting': 21.98\n",
        "        },\n",
        "        'IoT-23': {\n",
        "            'XGBoost': 0.61,\n",
        "            'RandomForest': 0.93,\n",
        "            'SVM': 6.82,\n",
        "            'MLP': 7.68,\n",
        "            'GradientBoosting': 9.68\n",
        "        }\n",
        "    }\n",
        "\n",
        "    models = list(training_data['CIC-IoT'].keys())\n",
        "    datasets = list(training_data.keys())\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.15\n",
        "\n",
        "    colors = {\n",
        "        'XGBoost': '#FF6B6B',\n",
        "        'RandomForest': '#4ECDC4',\n",
        "        'SVM': '#45B7D1',\n",
        "        'MLP': '#FFA07A',\n",
        "        'GradientBoosting': '#98D8C8'\n",
        "    }\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        values = [training_data[dataset][model] for dataset in datasets]\n",
        "        ax.bar(x + i * width, values, width, label=model, color=colors[model])\n",
        "\n",
        "    ax.set_ylabel('Training Time (seconds, log scale)', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Target Dataset', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Model Training Time Comparison Across Datasets',\n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x + width * 2)\n",
        "    ax.set_xticklabels(datasets)\n",
        "    ax.legend(title='Models', loc='upper left', framealpha=0.9)\n",
        "    ax.set_yscale('log')\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure1_Training_Time_Comparison.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Figure 1 saved: Figure1_Training_Time_Comparison.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "R_1o4FwCmb6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FIGURE 2: Class Distribution"
      ],
      "metadata": {
        "id": "BSsMsg69mt5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_figure2():\n",
        "    datasets = ['CICIOMT\\n(Source)', 'CIC-IoT\\n(Target)', 'IoT-23\\n(Target)']\n",
        "    dos_counts = [6999, 1500, 1500]\n",
        "    recon_counts = [2684, 136, 1500]\n",
        "    dos_percentages = [72.3, 91.7, 50.0]\n",
        "    recon_percentages = [27.7, 8.3, 50.0]\n",
        "    totals = [9683, 1636, 3000]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.35\n",
        "\n",
        "    dos_color = '#FF6B6B'\n",
        "    recon_color = '#4ECDC4'\n",
        "\n",
        "    bars1 = ax.bar(x - width/2, dos_counts, width, label='DoS',\n",
        "                   color=dos_color, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
        "    bars2 = ax.bar(x + width/2, recon_counts, width, label='Reconnaissance',\n",
        "                   color=recon_color, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "    for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
        "        height1 = bar1.get_height()\n",
        "        ax.text(bar1.get_x() + bar1.get_width()/2., height1,\n",
        "                f'{dos_counts[i]:,}\\n({dos_percentages[i]:.1f}%)',\n",
        "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "        height2 = bar2.get_height()\n",
        "        ax.text(bar2.get_x() + bar2.get_width()/2., height2,\n",
        "                f'{recon_counts[i]:,}\\n({recon_percentages[i]:.1f}%)',\n",
        "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    ax.set_ylabel('Sample Count', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Dataset', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Binary Class Distribution: DoS vs. Reconnaissance',\n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(datasets, fontsize=11)\n",
        "    ax.legend(loc='upper right', fontsize=11, framealpha=0.9)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    # FIXED: Adjust y-position and increase y-axis limit to prevent overlap\n",
        "    ax.set_ylim(-800, max(dos_counts) * 1.15)  # Extend downward for labels\n",
        "\n",
        "    for i, (x_pos, total) in enumerate(zip(x, totals)):\n",
        "        ax.text(x_pos, -650, f'Total: {total:,}',  # Changed from -500 to -650\n",
        "                ha='center', fontsize=10, fontweight='bold', color='darkblue')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure2_Class_Distribution_Simplified.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Figure 2 saved: Figure2_Class_Distribution_Simplified.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "Vg2rmNiqmw4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Enhancement Summary"
      ],
      "metadata": {
        "id": "YsJZetMJmz-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_figure3():\n",
        "    datasets = ['CIC-IoT', 'IoT-23']\n",
        "    common_features = [48, 0]\n",
        "    cybersecurity_features = [4, 4]\n",
        "    statistical_features = [8, 8]\n",
        "    pca_features = [0, 20]\n",
        "\n",
        "    colors = ['#FF6B6B', '#FFD93D', '#6BCF7F', '#4ECDC4']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.5\n",
        "\n",
        "    bottom = np.zeros(len(datasets))\n",
        "\n",
        "    feature_types = [\n",
        "        ('Common Features', common_features),\n",
        "        ('Cybersecurity Features', cybersecurity_features),\n",
        "        ('Statistical Features', statistical_features),\n",
        "        ('PCA Features', pca_features)\n",
        "    ]\n",
        "\n",
        "    for i, (label, values) in enumerate(feature_types):\n",
        "        bars = ax.bar(x, values, width, label=label, bottom=bottom,\n",
        "                     color=colors[i], alpha=0.85, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "        for j, (bar, val) in enumerate(zip(bars, values)):\n",
        "            if val > 0:\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2.,\n",
        "                       bottom[j] + height/2,\n",
        "                       f'{val}',\n",
        "                       ha='center', va='center', fontsize=11,\n",
        "                       fontweight='bold', color='white' if val > 5 else 'black')\n",
        "\n",
        "        bottom += values\n",
        "\n",
        "    totals = [60, 32]\n",
        "    for i, (x_pos, total) in enumerate(zip(x, totals)):\n",
        "        ax.text(x_pos, total + 1, f'Total: {total}',\n",
        "                ha='center', va='bottom', fontsize=12, fontweight='bold',\n",
        "                bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.3))\n",
        "\n",
        "    ax.set_ylabel('Number of Features', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Dataset', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Feature Enhancement Summary by Dataset',\n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(datasets, fontsize=12)\n",
        "    ax.legend(title='Feature Types', loc='upper right', framealpha=0.9, fontsize=10)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax.set_ylim(0, max(totals) + 8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure3_Feature_Enhancement_Summary.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Figure 3 saved: Figure3_Feature_Enhancement_Summary.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "nGbhwpubm2Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FIGURE 4: Final Transfer Learning Results - All Models"
      ],
      "metadata": {
        "id": "LFS7AANVuoTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_figure4():\n",
        "    models = ['Random\\nForest', 'Gradient\\nBoosting', 'XGBoost', 'SVM', 'MLP']\n",
        "    cic_iot_accuracy = [99.0, 98.9, 98.4, 80.0, 37.0]\n",
        "    iot_23_accuracy = [50.0, 50.0, 50.0, 50.0, 50.0]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 7))\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.35\n",
        "\n",
        "    cic_color = '#4ECDC4'\n",
        "    iot_color = '#FF6B6B'\n",
        "\n",
        "    bars1 = ax.bar(x - width/2, cic_iot_accuracy, width, label='CIC-IoT',\n",
        "                   color=cic_color, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
        "    bars2 = ax.bar(x + width/2, iot_23_accuracy, width, label='IoT-23',\n",
        "                   color=iot_color, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.1f}%',\n",
        "                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "    ax.axhline(y=99.0, color='green', linestyle='--', linewidth=2, alpha=0.5)\n",
        "    ax.axhline(y=50.0, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
        "\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Model', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Final Transfer Learning Results - All Models',\n",
        "                 fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(models, fontsize=12)\n",
        "\n",
        "    # FIXED: Move legend to better position\n",
        "    ax.legend(loc='center left', fontsize=11, framealpha=0.95,\n",
        "             bbox_to_anchor=(0.02, 0.5))\n",
        "\n",
        "    ax.set_ylim(0, 105)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure4_Final_Results_All_Models.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Figure 4 saved: Figure4_Final_Results_All_Models.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "iuiYuVT8m-ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FIGURE 6: Enhanced Transfer Learning System Architecture"
      ],
      "metadata": {
        "id": "YfbIVpnhutbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_figure6():\n",
        "    from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "    ax.set_xlim(0, 10)\n",
        "    ax.set_ylim(0, 10)\n",
        "    ax.axis('off')\n",
        "\n",
        "    blue = '#ADD8E6'\n",
        "    green = '#90EE90'\n",
        "    yellow = '#FFD700'\n",
        "    pink = '#FFB6C1'\n",
        "    purple = '#DDA0DD'\n",
        "    orange = '#FFA500'\n",
        "    gray = '#D3D3D3'\n",
        "\n",
        "    box_width = 3.5\n",
        "    box_height = 1.2\n",
        "\n",
        "    # 1. Raw Datasets\n",
        "    raw_box = FancyBboxPatch((3.25, 8.5), box_width, box_height,\n",
        "                             boxstyle=\"round,pad=0.1\",\n",
        "                             edgecolor='black', facecolor=blue, linewidth=2)\n",
        "    ax.add_patch(raw_box)\n",
        "    ax.text(5, 9.4, 'Raw Datasets', ha='center', va='center',\n",
        "            fontsize=14, fontweight='bold')\n",
        "    ax.text(5, 9.0, 'CICIoMT, CIC-IoT', ha='center', va='center', fontsize=11)\n",
        "    ax.text(5, 8.7, 'IoT-23', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 2. Preprocessing\n",
        "    prep_box = FancyBboxPatch((3.25, 6.8), box_width, box_height,\n",
        "                              boxstyle=\"round,pad=0.1\",\n",
        "                              edgecolor='black', facecolor=green, linewidth=2)\n",
        "    ax.add_patch(prep_box)\n",
        "    ax.text(5, 7.6, 'Preprocessing', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(5, 7.2, '& Label Mapping', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 3. Feature Alignment\n",
        "    align_box = FancyBboxPatch((0.5, 5.1), box_width, box_height,\n",
        "                               boxstyle=\"round,pad=0.1\",\n",
        "                               edgecolor='black', facecolor=yellow, linewidth=2)\n",
        "    ax.add_patch(align_box)\n",
        "    ax.text(2.25, 5.9, 'Enhanced Feature', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(2.25, 5.5, 'Alignment', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 4. Class Balancing\n",
        "    balance_box = FancyBboxPatch((6, 5.1), box_width, box_height,\n",
        "                                 boxstyle=\"round,pad=0.1\",\n",
        "                                 edgecolor='black', facecolor=pink, linewidth=2)\n",
        "    ax.add_patch(balance_box)\n",
        "    ax.text(7.75, 5.9, 'Class', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(7.75, 5.5, 'Balancing', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 5. Model Training\n",
        "    train_box = FancyBboxPatch((3.25, 3.4), box_width, box_height,\n",
        "                               boxstyle=\"round,pad=0.1\",\n",
        "                               edgecolor='black', facecolor=purple, linewidth=2)\n",
        "    ax.add_patch(train_box)\n",
        "    ax.text(5, 4.2, 'Model Training', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(5, 3.8, 'XGBoost, RF, SVM, MLP, GB', ha='center', va='center', fontsize=10)\n",
        "\n",
        "    # 6. Transfer Learning\n",
        "    transfer_box = FancyBboxPatch((3.25, 1.7), box_width, box_height,\n",
        "                                  boxstyle=\"round,pad=0.1\",\n",
        "                                  edgecolor='black', facecolor=orange, linewidth=2)\n",
        "    ax.add_patch(transfer_box)\n",
        "    ax.text(5, 2.5, 'Transfer Learning', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(5, 2.1, 'Optimization', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 7. Final Results\n",
        "    result_box = FancyBboxPatch((3.25, 0), box_width, box_height,\n",
        "                                boxstyle=\"round,pad=0.1\",\n",
        "                                edgecolor='black', facecolor=gray, linewidth=2)\n",
        "    ax.add_patch(result_box)\n",
        "    ax.text(5, 0.8, 'Final Results', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(5, 0.4, '99.0% Accuracy (CIC-IoT)', ha='center', va='center',\n",
        "            fontsize=11, fontweight='bold', color='green')\n",
        "\n",
        "    # Arrows\n",
        "    arrow_props = dict(arrowstyle='->', lw=2.5, color='black')\n",
        "\n",
        "    ax.add_patch(FancyArrowPatch((5, 8.5), (5, 8.0), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 6.8), (5, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 6.3), (2.25, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((2.25, 6.3), (2.25, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 6.3), (7.75, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((7.75, 6.3), (7.75, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((2.25, 5.1), (5, 4.6), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((7.75, 5.1), (5, 4.6), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 3.4), (5, 2.9), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 1.7), (5, 1.2), **arrow_props))\n",
        "\n",
        "    ax.set_title('Enhanced Transfer Learning System Architecture',\n",
        "                 fontsize=18, fontweight='bold', pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure6_System_Architecture.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Figure 6 saved: Figure6_System_Architecture.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "bpa-Y3F1uzb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Figure7: Transfer Learning Performance Evolution"
      ],
      "metadata": {
        "id": "V7aBBiEWu3I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_figure7():\n",
        "    phases = ['Initial\\nMisalignment', 'Basic\\nAlignment', 'Class\\nBalancing',\n",
        "              'Enhanced\\nAlignment', 'Final\\nOptimization']\n",
        "\n",
        "    cic_iot_evolution = [45, 72, 85, 92, 99.0]\n",
        "    iot_23_evolution = [35, 58, 72, 82, 50.0]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 7))\n",
        "    x = np.arange(len(phases))\n",
        "\n",
        "    line1 = ax.plot(x, cic_iot_evolution, marker='o', markersize=10,\n",
        "                    linewidth=3, color='#2E7D32', label='CIC-IoT (Successful Transfer)',\n",
        "                    markerfacecolor='#4CAF50', markeredgecolor='black', markeredgewidth=2)\n",
        "\n",
        "    line2 = ax.plot(x, iot_23_evolution, marker='s', markersize=10,\n",
        "                    linewidth=3, color='#C62828', label='IoT-23 (Failed Transfer)',\n",
        "                    markerfacecolor='#EF5350', markeredgecolor='black', markeredgewidth=2,\n",
        "                    linestyle='--')\n",
        "\n",
        "    for i, (val1, val2) in enumerate(zip(cic_iot_evolution, iot_23_evolution)):\n",
        "        ax.text(i, val1 + 2, f'{val1:.1f}%', ha='center', va='bottom',\n",
        "               fontsize=11, fontweight='bold', color='#2E7D32',\n",
        "               bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))\n",
        "        ax.text(i, val2 - 2, f'{val2:.1f}%', ha='center', va='top',\n",
        "               fontsize=11, fontweight='bold', color='#C62828',\n",
        "               bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7))\n",
        "\n",
        "    ax.axhline(y=99.0, color='green', linestyle=':', linewidth=2, alpha=0.5)\n",
        "    ax.axhline(y=50.0, color='red', linestyle=':', linewidth=2, alpha=0.5)\n",
        "\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Development Phase', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Transfer Learning Performance Evolution',\n",
        "                 fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(phases, fontsize=11)\n",
        "    ax.legend(loc='lower right', fontsize=12, framealpha=0.95)\n",
        "    ax.set_ylim(25, 105)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "    success_note = \"48 common features\\nProtocol similarity\\nDomain compatibility\"\n",
        "    ax.text(0.98, 0.82, success_note, transform=ax.transAxes,\n",
        "           fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
        "           bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
        "\n",
        "    failure_note = \"0 common features\\nSemantic domain shift\\nProtocol mismatch\"\n",
        "    ax.text(0.98, 0.35, failure_note, transform=ax.transAxes,\n",
        "           fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
        "           bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure7_Performance_Evolution.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Figure 7 saved: Figure7_Performance_Evolution.png\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "efMY3IxDu5kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating thesis figures with actual experimental results...\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    create_figure1()\n",
        "    create_figure2()\n",
        "    create_figure3()\n",
        "    create_figure4()\n",
        "    create_figure6()  # Now with fixed imports\n",
        "    create_figure7()\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"All figures generated successfully!\")\n",
        "    print(\"\\nGenerated files:\")\n",
        "    print(\"  1. Figure1_Training_Time_Comparison.png\")\n",
        "    print(\"  2. Figure2_Class_Distribution_Simplified.png\")\n",
        "    print(\"  3. Figure3_Feature_Enhancement_Summary.png\")\n",
        "    print(\"  4. Figure4_Final_Results_All_Models.png\")\n",
        "    print(\"  6. Figure6_System_Architecture.png\")\n",
        "    print(\"  7. Figure7_Performance_Evolution.png\")\n",
        "    print(\"\\nAll figures are publication-ready at 300 DPI\")"
      ],
      "metadata": {
        "id": "ApvRVERsu-xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "THESIS FIGURES - CHAPTER 5: DESIGN, IMPLEMENTATION, AND EXPERIMENTAL ANALYSIS\n",
        "Complete figure generation script with proper numbering and documentation\n",
        "\n",
        "Author: Oluwaseyi Oladejo\n",
        "Date: November 2025\n",
        "Thesis: Leveraging Cross-Domain Transfer Learning for Enhanced Multi-Protocol Network Intrusion Detection\n",
        "\n",
        "FIGURE ORDER (as they appear in Chapter 5):\n",
        "- Figure 1: Feature Enhancement Summary by Dataset (Section 5.2.2)\n",
        "- Figure 2: Feature Alignment Before and After Enhancement (Section 5.3)\n",
        "- Figure 3: Binary Class Distribution - DoS vs. Reconnaissance (Section 5.4)\n",
        "- Figure 4: Model Training Time Comparison Across Datasets (Section 5.5)\n",
        "- Figure 5: Final Transfer Learning Results - All Models (Section 5.6)\n",
        "- Figure 6: Transfer Learning Performance Evolution (Section 5.6)\n",
        "- Figure 7: Enhanced Transfer Learning System Architecture (Section 5.7)\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
        "\n",
        "# Set publication-quality style\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FIGURE 1: Feature Enhancement Summary by Dataset\n",
        "# Location: Section 5.2.2 - Feature Engineering and Augmentation\n",
        "# ============================================================================\n",
        "\n",
        "def create_figure1_feature_enhancement():\n",
        "    \"\"\"\n",
        "    Stacked bar chart showing feature composition breakdown:\n",
        "    - CIC-IoT: 48 common + 4 cyber + 8 stat + 0 PCA = 60 total\n",
        "    - IoT-23: 0 common + 4 cyber + 8 stat + 20 PCA = 32 total\n",
        "    \"\"\"\n",
        "    print(\"Generating Figure 1: Feature Enhancement Summary...\")\n",
        "\n",
        "    datasets = ['CIC-IoT', 'IoT-23']\n",
        "    common_features = [48, 0]\n",
        "    cybersecurity_features = [4, 4]\n",
        "    statistical_features = [8, 8]\n",
        "    pca_features = [0, 20]\n",
        "\n",
        "    colors = ['#FF6B6B', '#FFD93D', '#6BCF7F', '#4ECDC4']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.5\n",
        "    bottom = np.zeros(len(datasets))\n",
        "\n",
        "    feature_types = [\n",
        "        ('Common Features', common_features),\n",
        "        ('Cybersecurity Features', cybersecurity_features),\n",
        "        ('Statistical Features', statistical_features),\n",
        "        ('PCA Features', pca_features)\n",
        "    ]\n",
        "\n",
        "    for i, (label, values) in enumerate(feature_types):\n",
        "        bars = ax.bar(x, values, width, label=label, bottom=bottom,\n",
        "                     color=colors[i], alpha=0.85, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "        for j, (bar, val) in enumerate(zip(bars, values)):\n",
        "            if val > 0:\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2.,\n",
        "                       bottom[j] + height/2, f'{val}',\n",
        "                       ha='center', va='center', fontsize=11,\n",
        "                       fontweight='bold', color='white' if val > 5 else 'black')\n",
        "        bottom += values\n",
        "\n",
        "    totals = [60, 32]\n",
        "    for i, (x_pos, total) in enumerate(zip(x, totals)):\n",
        "        ax.text(x_pos, total + 1, f'Total: {total}',\n",
        "                ha='center', va='bottom', fontsize=12, fontweight='bold',\n",
        "                bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.3))\n",
        "\n",
        "    ax.set_ylabel('Number of Features', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Dataset', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Feature Enhancement Summary by Dataset',\n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(datasets, fontsize=12)\n",
        "    ax.legend(title='Feature Types', loc='upper right', framealpha=0.9, fontsize=10)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax.set_ylim(0, max(totals) + 8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure1_Feature_Enhancement_Summary.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"  Saved: Figure1_Feature_Enhancement_Summary.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FIGURE 2: Feature Alignment Before and After Enhancement\n",
        "# Location: Section 5.3 - Feature Alignment for Transfer Learning\n",
        "# ============================================================================\n",
        "\n",
        "def create_figure2_feature_alignment():\n",
        "    \"\"\"\n",
        "    Side-by-side comparison showing transformation:\n",
        "    - BEFORE: CICIoT (44 features), IoT-23 (0 features)\n",
        "    - AFTER: CICIoT (73 features), IoT-23 (29 features)\n",
        "    \"\"\"\n",
        "    print(\"Generating Figure 2: Feature Alignment Before/After...\")\n",
        "\n",
        "    datasets = ['CICIoT', 'IoT-23']\n",
        "    before_features = [44, 0]\n",
        "    after_features = [73, 29]\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    problem_color = '#FF6B6B'\n",
        "    success_color = '#6BCF7F'\n",
        "\n",
        "    # LEFT: Before Alignment\n",
        "    x1 = np.arange(len(datasets))\n",
        "    bars_before = ax1.bar(x1, before_features, width=0.6,\n",
        "                          color=problem_color, alpha=0.85,\n",
        "                          edgecolor='black', linewidth=2)\n",
        "\n",
        "    for i, (bar, val) in enumerate(zip(bars_before, before_features)):\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., val + 1,\n",
        "                f'{val}', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax1.set_ylabel('Number of Features', fontsize=13, fontweight='bold')\n",
        "    ax1.set_xlabel('Dataset', fontsize=13, fontweight='bold')\n",
        "    ax1.set_title('Before: Feature Misalignment Problem',\n",
        "                  fontsize=14, fontweight='bold', pad=15, color='darkred')\n",
        "    ax1.set_xticks(x1)\n",
        "    ax1.set_xticklabels(datasets, fontsize=12)\n",
        "    ax1.set_ylim(0, 80)\n",
        "    ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax1.text(0.5, 0.95, 'Feature overlap issue:\\nIoT-23 has ZERO common features',\n",
        "            transform=ax1.transAxes, ha='center', va='top',\n",
        "            fontsize=10, bbox=dict(boxstyle='round,pad=0.5',\n",
        "            facecolor='lightcoral', alpha=0.7))\n",
        "\n",
        "    # RIGHT: After Alignment\n",
        "    x2 = np.arange(len(datasets))\n",
        "    bars_after = ax2.bar(x2, after_features, width=0.6,\n",
        "                         color=success_color, alpha=0.85,\n",
        "                         edgecolor='black', linewidth=2)\n",
        "\n",
        "    for i, (bar, val) in enumerate(zip(bars_after, after_features)):\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., val + 1,\n",
        "                f'{val}', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax2.text(0, 73 - 10, '48 common\\n+4 cyber\\n+8 stat\\n+13 PCA',\n",
        "            ha='center', va='top', fontsize=9,\n",
        "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
        "\n",
        "    ax2.text(1, 29 - 5, '0 common\\n+4 cyber\\n+8 stat\\n+17 PCA',\n",
        "            ha='center', va='top', fontsize=9,\n",
        "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
        "\n",
        "    ax2.set_ylabel('Number of Features', fontsize=13, fontweight='bold')\n",
        "    ax2.set_xlabel('Dataset', fontsize=13, fontweight='bold')\n",
        "    ax2.set_title('After: Enhanced Alignment Success',\n",
        "                  fontsize=14, fontweight='bold', pad=15, color='darkgreen')\n",
        "    ax2.set_xticks(x2)\n",
        "    ax2.set_xticklabels(datasets, fontsize=12)\n",
        "    ax2.set_ylim(0, 80)\n",
        "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax2.text(0.5, 0.95, 'Solution: Feature engineering\\nenables transfer learning evaluation',\n",
        "            transform=ax2.transAxes, ha='center', va='top',\n",
        "            fontsize=10, bbox=dict(boxstyle='round,pad=0.5',\n",
        "            facecolor='lightgreen', alpha=0.7))\n",
        "\n",
        "    fig.suptitle('Feature Alignment Before and After Enhancement',\n",
        "                 fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure2_Feature_Alignment_BeforeAfter.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"  Saved: Figure2_Feature_Alignment_BeforeAfter.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FIGURE 3: Binary Class Distribution - DoS vs. Reconnaissance\n",
        "# Location: Section 5.4 - Addressing Class Imbalance Via Hybrid Balancing\n",
        "# ============================================================================\n",
        "\n",
        "def create_figure3_class_distribution():\n",
        "    \"\"\"\n",
        "    Bar chart showing class distribution across source and target datasets:\n",
        "    - CICIoMT: 6,999 DoS (72.3%), 2,684 Recon (27.7%)\n",
        "    - CICIoT: 1,500 DoS (91.7%), 136 Recon (8.3%)\n",
        "    - IoT-23: 1,500 DoS (50%), 1,500 Recon (50%)\n",
        "    \"\"\"\n",
        "    print(\"Generating Figure 3: Class Distribution...\")\n",
        "\n",
        "    datasets = ['CICIOMT\\n(Source)', 'CICIoT\\n(Target)', 'IoT-23\\n(Target)']\n",
        "    dos_counts = [6999, 1500, 1500]\n",
        "    recon_counts = [2684, 136, 1500]\n",
        "    dos_percentages = [72.3, 91.7, 50.0]\n",
        "    recon_percentages = [27.7, 8.3, 50.0]\n",
        "    totals = [9683, 1636, 3000]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.35\n",
        "\n",
        "    dos_color = '#FF6B6B'\n",
        "    recon_color = '#4ECDC4'\n",
        "\n",
        "    bars1 = ax.bar(x - width/2, dos_counts, width, label='DoS',\n",
        "                   color=dos_color, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
        "    bars2 = ax.bar(x + width/2, recon_counts, width, label='Reconnaissance',\n",
        "                   color=recon_color, alpha=0.8, edgecolor='black', linewidth=1.2)\n",
        "\n",
        "    for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
        "        height1 = bar1.get_height()\n",
        "        ax.text(bar1.get_x() + bar1.get_width()/2., height1,\n",
        "                f'{dos_counts[i]:,}\\n({dos_percentages[i]:.1f}%)',\n",
        "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "        height2 = bar2.get_height()\n",
        "        ax.text(bar2.get_x() + bar2.get_width()/2., height2,\n",
        "                f'{recon_counts[i]:,}\\n({recon_percentages[i]:.1f}%)',\n",
        "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    ax.set_ylabel('Sample Count', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Dataset', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Binary Class Distribution: DoS vs. Reconnaissance',\n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(datasets, fontsize=11)\n",
        "    ax.legend(loc='upper right', fontsize=11, framealpha=0.9)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax.set_ylim(-800, max(dos_counts) * 1.15)\n",
        "\n",
        "    for i, (x_pos, total) in enumerate(zip(x, totals)):\n",
        "        ax.text(x_pos, -650, f'Total: {total:,}',\n",
        "                ha='center', fontsize=10, fontweight='bold', color='darkblue')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure3_Class_Distribution.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"  Saved: Figure3_Class_Distribution.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FIGURE 4: Model Training Time Comparison\n",
        "# Location: Section 5.5 - Multi-Model Transfer Learning Implementation\n",
        "# ============================================================================\n",
        "\n",
        "def create_figure4_training_time():\n",
        "    \"\"\"\n",
        "    Log-scale bar chart showing training times for 5 models on 2 datasets\n",
        "    \"\"\"\n",
        "    print(\"Generating Figure 4: Training Time Comparison...\")\n",
        "\n",
        "    training_data = {\n",
        "        'CIC-IoT': {\n",
        "            'XGBoost': 1.00,\n",
        "            'RandomForest': 1.70,\n",
        "            'SVM': 0.57,\n",
        "            'MLP': 13.84,\n",
        "            'GradientBoosting': 21.98\n",
        "        },\n",
        "        'IoT-23': {\n",
        "            'XGBoost': 0.61,\n",
        "            'RandomForest': 0.93,\n",
        "            'SVM': 6.82,\n",
        "            'MLP': 7.68,\n",
        "            'GradientBoosting': 9.68\n",
        "        }\n",
        "    }\n",
        "\n",
        "    models = list(training_data['CIC-IoT'].keys())\n",
        "    datasets = list(training_data.keys())\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.15\n",
        "\n",
        "    colors = {\n",
        "        'XGBoost': '#FF6B6B',\n",
        "        'RandomForest': '#4ECDC4',\n",
        "        'SVM': '#45B7D1',\n",
        "        'MLP': '#FFA07A',\n",
        "        'GradientBoosting': '#98D8C8'\n",
        "    }\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        values = [training_data[dataset][model] for dataset in datasets]\n",
        "        ax.bar(x + i * width, values, width, label=model, color=colors[model])\n",
        "\n",
        "    ax.set_ylabel('Training Time (seconds, log scale)', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Target Dataset', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Model Training Time Comparison Across Datasets',\n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x + width * 2)\n",
        "    ax.set_xticklabels(datasets)\n",
        "    ax.legend(title='Models', loc='upper left', framealpha=0.9)\n",
        "    ax.set_yscale('log')\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure4_Training_Time_Comparison.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"  Saved: Figure4_Training_Time_Comparison.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FIGURE 5: Final Transfer Learning Results - All Models\n",
        "# Location: Section 5.6 - Experimental Progression (first figure)\n",
        "# ============================================================================\n",
        "\n",
        "def create_figure5_final_results():\n",
        "    \"\"\"\n",
        "    Bar chart showing actual experimental results:\n",
        "    - CIC-IoT: RF=99%, GB=98.9%, XGB=98.4%, SVM=80%, MLP=37%\n",
        "    - IoT-23: All models=50%\n",
        "    \"\"\"\n",
        "    print(\"Generating Figure 5: Final Results All Models...\")\n",
        "\n",
        "    models = ['Random\\nForest', 'Gradient\\nBoosting', 'XGBoost', 'SVM', 'MLP']\n",
        "    cic_iot_accuracy = [99.0, 98.9, 98.4, 80.0, 37.0]\n",
        "    iot_23_accuracy = [50.0, 50.0, 50.0, 50.0, 50.0]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 7))\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.35\n",
        "\n",
        "    cic_color = '#4ECDC4'\n",
        "    iot_color = '#FF6B6B'\n",
        "\n",
        "    bars1 = ax.bar(x - width/2, cic_iot_accuracy, width, label='CIC-IoT',\n",
        "                   color=cic_color, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
        "    bars2 = ax.bar(x + width/2, iot_23_accuracy, width, label='IoT-23',\n",
        "                   color=iot_color, alpha=0.85, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.1f}%', ha='center', va='bottom',\n",
        "                   fontsize=11, fontweight='bold')\n",
        "\n",
        "    ax.axhline(y=99.0, color='green', linestyle='--', linewidth=2, alpha=0.5)\n",
        "    ax.axhline(y=50.0, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
        "\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Model', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Final Transfer Learning Results - All Models',\n",
        "                 fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(models, fontsize=12)\n",
        "    ax.legend(loc='center left', fontsize=11, framealpha=0.95,\n",
        "             bbox_to_anchor=(0.02, 0.5))\n",
        "    ax.set_ylim(0, 105)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure5_Final_Results_All_Models.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"  Saved: Figure5_Final_Results_All_Models.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FIGURE 6: Transfer Learning Performance Evolution\n",
        "# Location: Section 5.6 - Experimental Progression (second figure)\n",
        "# ============================================================================\n",
        "\n",
        "def create_figure6_performance_evolution():\n",
        "    \"\"\"\n",
        "    Line chart showing performance evolution across 5 development phases:\n",
        "    - CIC-IoT: 45%  72%  85%  92%  99%\n",
        "    - IoT-23: 35%  58%  72%  82%  50%\n",
        "    \"\"\"\n",
        "    print(\"Generating Figure 6: Performance Evolution...\")\n",
        "\n",
        "    phases = ['Initial\\nMisalignment', 'Basic\\nAlignment', 'Class\\nBalancing',\n",
        "              'Enhanced\\nAlignment', 'Final\\nOptimization']\n",
        "\n",
        "    cic_iot_evolution = [45, 72, 85, 92, 99.0]\n",
        "    iot_23_evolution = [35, 58, 72, 82, 50.0]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 7))\n",
        "    x = np.arange(len(phases))\n",
        "\n",
        "    line1 = ax.plot(x, cic_iot_evolution, marker='o', markersize=10,\n",
        "                    linewidth=3, color='#2E7D32', label='CIC-IoT (Successful Transfer)',\n",
        "                    markerfacecolor='#4CAF50', markeredgecolor='black', markeredgewidth=2)\n",
        "\n",
        "    line2 = ax.plot(x, iot_23_evolution, marker='s', markersize=10,\n",
        "                    linewidth=3, color='#C62828', label='IoT-23 (Failed Transfer)',\n",
        "                    markerfacecolor='#EF5350', markeredgecolor='black', markeredgewidth=2,\n",
        "                    linestyle='--')\n",
        "\n",
        "    for i, (val1, val2) in enumerate(zip(cic_iot_evolution, iot_23_evolution)):\n",
        "        ax.text(i, val1 + 2, f'{val1:.1f}%', ha='center', va='bottom',\n",
        "               fontsize=11, fontweight='bold', color='#2E7D32',\n",
        "               bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))\n",
        "        ax.text(i, val2 - 2, f'{val2:.1f}%', ha='center', va='top',\n",
        "               fontsize=11, fontweight='bold', color='#C62828',\n",
        "               bbox=dict(boxstyle='round,pad=0.3', facecolor='lightcoral', alpha=0.7))\n",
        "\n",
        "    ax.axhline(y=99.0, color='green', linestyle=':', linewidth=2, alpha=0.5)\n",
        "    ax.axhline(y=50.0, color='red', linestyle=':', linewidth=2, alpha=0.5)\n",
        "\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Development Phase', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Transfer Learning Performance Evolution',\n",
        "                 fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(phases, fontsize=11)\n",
        "    ax.legend(loc='lower right', fontsize=12, framealpha=0.95)\n",
        "    ax.set_ylim(25, 105)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "    success_note = \"48 common features\\nProtocol similarity\\nDomain compatibility\"\n",
        "    ax.text(0.98, 0.82, success_note, transform=ax.transAxes,\n",
        "           fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
        "           bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
        "\n",
        "    failure_note = \"0 common features\\nSemantic domain shift\\nProtocol mismatch\"\n",
        "    ax.text(0.98, 0.35, failure_note, transform=ax.transAxes,\n",
        "           fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
        "           bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure6_Performance_Evolution.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"  Saved: Figure6_Performance_Evolution.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# FIGURE 7: Enhanced Transfer Learning System Architecture\n",
        "# Location: Section 5.7 - System Architecture Overview\n",
        "# ============================================================================\n",
        "\n",
        "def create_figure7_system_architecture():\n",
        "    \"\"\"\n",
        "    Flowchart showing the 7-stage transfer learning pipeline\n",
        "    \"\"\"\n",
        "    print(\"Generating Figure 7: System Architecture...\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "    ax.set_xlim(0, 10)\n",
        "    ax.set_ylim(0, 10)\n",
        "    ax.axis('off')\n",
        "\n",
        "    blue = '#ADD8E6'\n",
        "    green = '#90EE90'\n",
        "    yellow = '#FFD700'\n",
        "    pink = '#FFB6C1'\n",
        "    purple = '#DDA0DD'\n",
        "    orange = '#FFA500'\n",
        "    gray = '#D3D3D3'\n",
        "\n",
        "    box_width = 3.5\n",
        "    box_height = 1.2\n",
        "\n",
        "    # 1. Raw Datasets\n",
        "    raw_box = FancyBboxPatch((3.25, 8.5), box_width, box_height,\n",
        "                             boxstyle=\"round,pad=0.1\",\n",
        "                             edgecolor='black', facecolor=blue, linewidth=2)\n",
        "    ax.add_patch(raw_box)\n",
        "    ax.text(5, 9.4, 'Raw Datasets', ha='center', va='center',\n",
        "            fontsize=14, fontweight='bold')\n",
        "    ax.text(5, 9.0, 'CICIoMT, CICIoT', ha='center', va='center', fontsize=11)\n",
        "    ax.text(5, 8.7, 'IoT-23', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 2. Preprocessing\n",
        "    prep_box = FancyBboxPatch((3.25, 6.8), box_width, box_height,\n",
        "                              boxstyle=\"round,pad=0.1\",\n",
        "                              edgecolor='black', facecolor=green, linewidth=2)\n",
        "    ax.add_patch(prep_box)\n",
        "    ax.text(5, 7.6, 'Preprocessing', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(5, 7.2, '& Label Mapping', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 3. Feature Alignment\n",
        "    align_box = FancyBboxPatch((0.5, 5.1), box_width, box_height,\n",
        "                               boxstyle=\"round,pad=0.1\",\n",
        "                               edgecolor='black', facecolor=yellow, linewidth=2)\n",
        "    ax.add_patch(align_box)\n",
        "    ax.text(2.25, 5.9, 'Enhanced Feature', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(2.25, 5.5, 'Alignment', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 4. Class Balancing\n",
        "    balance_box = FancyBboxPatch((6, 5.1), box_width, box_height,\n",
        "                                 boxstyle=\"round,pad=0.1\",\n",
        "                                 edgecolor='black', facecolor=pink, linewidth=2)\n",
        "    ax.add_patch(balance_box)\n",
        "    ax.text(7.75, 5.9, 'Class', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(7.75, 5.5, 'Balancing', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 5. Model Training\n",
        "    train_box = FancyBboxPatch((3.25, 3.4), box_width, box_height,\n",
        "                               boxstyle=\"round,pad=0.1\",\n",
        "                               edgecolor='black', facecolor=purple, linewidth=2)\n",
        "    ax.add_patch(train_box)\n",
        "    ax.text(5, 4.2, 'Model Training', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(5, 3.8, 'XGBoost, RF, SVM, MLP, GB', ha='center', va='center', fontsize=10)\n",
        "\n",
        "    # 6. Transfer Learning\n",
        "    transfer_box = FancyBboxPatch((3.25, 1.7), box_width, box_height,\n",
        "                                  boxstyle=\"round,pad=0.1\",\n",
        "                                  edgecolor='black', facecolor=orange, linewidth=2)\n",
        "    ax.add_patch(transfer_box)\n",
        "    ax.text(5, 2.5, 'Transfer Learning', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(5, 2.1, 'Optimization', ha='center', va='center', fontsize=11)\n",
        "\n",
        "    # 7. Final Results\n",
        "    result_box = FancyBboxPatch((3.25, 0), box_width, box_height,\n",
        "                                boxstyle=\"round,pad=0.1\",\n",
        "                                edgecolor='black', facecolor=gray, linewidth=2)\n",
        "    ax.add_patch(result_box)\n",
        "    ax.text(5, 0.8, 'Final Results', ha='center', va='center',\n",
        "            fontsize=13, fontweight='bold')\n",
        "    ax.text(5, 0.4, '99.0% Accuracy (CIC-IoT)', ha='center', va='center',\n",
        "            fontsize=11, fontweight='bold', color='green')\n",
        "\n",
        "    # Arrows\n",
        "    arrow_props = dict(arrowstyle='->', lw=2.5, color='black')\n",
        "\n",
        "    ax.add_patch(FancyArrowPatch((5, 8.5), (5, 8.0), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 6.8), (5, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 6.3), (2.25, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((2.25, 6.3), (2.25, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 6.3), (7.75, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((7.75, 6.3), (7.75, 6.3), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((2.25, 5.1), (5, 4.6), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((7.75, 5.1), (5, 4.6), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 3.4), (5, 2.9), **arrow_props))\n",
        "    ax.add_patch(FancyArrowPatch((5, 1.7), (5, 1.2), **arrow_props))\n",
        "\n",
        "    ax.set_title('Enhanced Transfer Learning System Architecture',\n",
        "                 fontsize=18, fontweight='bold', pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Figure7_System_Architecture.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"  Saved: Figure7_System_Architecture.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION - Generate ALL figures in correct order\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"GENERATING ALL THESIS FIGURES - CHAPTER 5\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    create_figure1_feature_enhancement()\n",
        "    create_figure2_feature_alignment()\n",
        "    create_figure3_class_distribution()\n",
        "    create_figure4_training_time()\n",
        "    create_figure5_final_results()\n",
        "    create_figure6_performance_evolution()\n",
        "    create_figure7_system_architecture()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ALL FIGURES GENERATED SUCCESSFULLY!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated files (in order):\")\n",
        "    print(\"  1. Figure1_Feature_Enhancement_Summary.png (Section 5.2.2)\")\n",
        "    print(\"  2. Figure2_Feature_Alignment_BeforeAfter.png (Section 5.3)\")\n",
        "    print(\"  3. Figure3_Class_Distribution.png (Section 5.4)\")\n",
        "    print(\"  4. Figure4_Training_Time_Comparison.png (Section 5.5)\")\n",
        "    print(\"  5. Figure5_Final_Results_All_Models.png (Section 5.6)\")\n",
        "    print(\"  6. Figure6_Performance_Evolution.png (Section 5.6)\")\n",
        "    print(\"  7. Figure7_System_Architecture.png (Section 5.7)\")\n",
        "    print(\"\\nAll figures are publication-ready at 300 DPI\")\n",
        "    print(\"=\"*70 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "VeV2QNQFEkvv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}